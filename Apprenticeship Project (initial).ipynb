{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4798a73c-1fd0-4d93-8641-066f2d7ec2f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from prophet import Prophet\n",
    "from pyspark.sql.functions import to_date, to_timestamp, col, last, when, lit, dayofweek, dayofmonth, dayofyear, month, weekofyear, current_date, date_sub, datediff\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import ticker\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import joblib\n",
    "import holidays\n",
    "\n",
    "df = spark.read.table('data_experience_commercial.cbt_1423_rtsuite.master').select('charge_dt','dtg','chargeproduct','unt_pre','flightkey','flight_dt','rev_pre','channel')\n",
    "dmh = spark.read.table('data_experience_commercial.cbt_0923_segmentfinder.dimensions_history').select('flightkey','onsale_dt','ty_capacity','routetype','region')\n",
    "#pi = spark.read.table('data_prod.silver_sanezdb.priceinspection').select('segment','when','promoseats')\n",
    "#pi = pi.withColumnRenamed('segment', 'flightkey')\n",
    "#pi = pi.withColumnRenamed('when', 'charge_dt')\n",
    "#pi = pi.withColumn('charge_dt', to_date('charge_dt'))\n",
    "#pi = pi.withColumn('promoseats', col('promoseats').cast('int'))\n",
    "#pi = pi.fillna({'promoseats': 0})\n",
    "#pi = pi.groupby('flightkey','charge_dt').agg(F.max('promoseats').alias('promoseats')).orderBy('flightkey','charge_dt')\n",
    "#df = df.join(dmh, on='flightkey', how='left').join(pi, on=['flightkey','charge_dt'], how='left').drop('flightkey')\n",
    "df = df.join(dmh, on='flightkey', how='left')\n",
    "df = df[(df['chargeproduct']=='Ticket') & (df['dtg'] >= 0) & (df['region'].isin(['UK-London','UK-Regions'])) & (df['routetype'] == 'Domestic')]\n",
    "df = df.filter((col('dtg') < (datediff(col('flight_dt'), col('onsale_dt')) - 25)) & (col('charge_dt') >= '2019-01-01'))\n",
    "df = df.withColumn('unt_pre', F.when(col('unt_pre') < 0, 0).otherwise(col('unt_pre')))\n",
    "df = df.withColumn('rev_pre', F.when(col('rev_pre') < 0, 0).otherwise(col('rev_pre')))\n",
    "df = df.withColumn('channel_index', when(col('channel') == 'Web/App', 1).otherwise(0))\n",
    "#df = df.groupby('charge_dt','dtg').agg(F.sum('unt_pre').alias('unt_pre'), F.sum('rev_pre').alias('rev_pre'), F.sum('ty_capacity').alias('ty_capacity'), F.sum('promoseats').alias('promoseats')).orderBy('charge_dt','dtg')\n",
    "df = df.groupby('charge_dt','dtg').agg(F.sum('unt_pre').alias('unt_pre'), F.sum('rev_pre').alias('rev_pre'), F.sum('ty_capacity').alias('ty_capacity'), F.avg('channel_index').alias('channel_mix')).orderBy('charge_dt','dtg')\n",
    "#df=df.fillna({'promoseats': 0})\n",
    "df = df.toPandas()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0a7dc93-5606-433e-93fe-a0628e41ff4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lag_days = [7, 14, 21, 28, 364]\n",
    "cols_to_lag = ['unt_pre', 'channel_mix']\n",
    "\n",
    "def generate_lag_features(df, value_columns, lag_days, date_col='charge_dt', dtg_col='dtg'):\n",
    "    \"\"\"\n",
    "    Generate lag features for multiple value columns at specified lag days.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "    - value_columns: list of column names to generate lag features for\n",
    "    - lag_days: list of integers, each representing a lag in days\n",
    "    - date_col: name of the charge date column\n",
    "    - dtg_col: name of the dtg column (to group by)\n",
    "    \n",
    "    Returns:\n",
    "    - df with added lag features\n",
    "    \"\"\"\n",
    "    df = df.sort_values([dtg_col, date_col])\n",
    "    df = df.set_index([date_col, dtg_col])\n",
    "\n",
    "    for col in value_columns:\n",
    "        for lag in lag_days:\n",
    "            lag_col_name = f'{col}_lag{lag}'\n",
    "            df[lag_col_name] = df.groupby(level=1)[col].shift(lag)\n",
    "\n",
    "    return df.reset_index()\n",
    "\n",
    "df = generate_lag_features(df, cols_to_lag, lag_days)\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f23e830-a3b4-4d1d-93f6-f2814f9fa71f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "df['charge_dt'] = pd.to_datetime(df['charge_dt'])\n",
    "\n",
    "df['rev_pre'] = df['rev_pre'].round(0).astype(int)\n",
    "df['yield'] = df['rev_pre'] / df['unt_pre']\n",
    "df['yield'] = df['yield'].fillna(0) \n",
    "df['yield'] = df['yield'].round(0).astype(int)\n",
    "df.drop(['rev_pre'], axis=1, inplace=True)\n",
    "df.drop(['channel_mix'], axis=1, inplace=True)\n",
    "\n",
    "def create_features(df):\n",
    "    df['flight_dt'] = pd.to_datetime(df['charge_dt'] + pd.to_timedelta(df['dtg'], unit='D'))\n",
    "    df['charge_dt'] = pd.to_datetime(df['charge_dt'])\n",
    "\n",
    "    df['flight_month'] = df['flight_dt'].dt.month.astype(str)\n",
    "    df['flight_dow'] = df['flight_dt'].dt.dayofweek.astype(str)\n",
    "    df['flight_dom'] = df['flight_dt'].dt.day.astype(str)\n",
    "    df['flight_doy'] = df['flight_dt'].dt.dayofyear.astype(str)\n",
    "    df['flight_year'] = df['flight_dt'].dt.year.astype(str)\n",
    "\n",
    "    df['charge_month'] = df['charge_dt'].dt.month.astype(str)\n",
    "    df['charge_dow'] = df['charge_dt'].dt.dayofweek.astype(str)\n",
    "    df['charge_dom'] = df['charge_dt'].dt.day.astype(str)\n",
    "    df['charge_doy'] = df['charge_dt'].dt.dayofyear.astype(str)\n",
    "    df['charge_year'] = df['charge_dt'].dt.year.astype(str)\n",
    "\n",
    "    #df.set_index('charge_dt', inplace=True)\n",
    "    #df = df.sort_index()\n",
    "\n",
    "create_features(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5bc7276-f672-42b5-bb03-0280e6becff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uk_holidays = holidays.UK(years=range(2022, 2026))\n",
    "holidays_df = pd.DataFrame([(date, name) for date, name in uk_holidays.items()], columns=['ds', 'holiday'])\n",
    "holidays_df.sort_values(by='ds', inplace=True)\n",
    "holidays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81336b4-d197-41cd-9e5b-aca123500382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "additional_holidays = pd.DataFrame([\n",
    "    {'ds': '2022-04-18', 'holiday': 'Easter Monday'},\n",
    "    {'ds': '2022-08-29', 'holiday': 'Summer Bank Holiday'},\n",
    "    {'ds': '2023-04-10', 'holiday': 'Easter Monday'},\n",
    "    {'ds': '2023-08-28', 'holiday': 'Summer Bank Holiday'},\n",
    "    {'ds': '2024-04-01', 'holiday': 'Easter Monday'},\n",
    "    {'ds': '2024-08-26', 'holiday': 'Summer Bank Holiday'},\n",
    "    {'ds': '2025-04-21', 'holiday': 'Easter Monday'},\n",
    "    {'ds': '2025-08-25', 'holiday': 'Summer Bank Holiday'},\n",
    "])\n",
    "holidays_df = pd.concat([holidays_df, additional_holidays], ignore_index=True)\n",
    "holidays_df.drop_duplicates(inplace=True)\n",
    "holidays_df['ds'] = pd.to_datetime(holidays_df['ds'])\n",
    "holidays_df.sort_values(by='ds', inplace=True)\n",
    "holidays_df.reset_index(drop=True, inplace=True)\n",
    "holidays_df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1be869-8f30-48c2-ab6a-0e2015be9d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "holidays_df[\"ds\"] = pd.to_datetime(holidays_df[\"ds\"])\n",
    "df = df.merge(holidays_df.rename(columns={'ds': 'charge_dt', 'holiday': 'charge_dt_holiday'}), how='left', on='charge_dt')\n",
    "df = df.merge(holidays_df.rename(columns={'ds': 'flight_dt', 'holiday': 'flight_dt_holiday'}), how='left', on='flight_dt')\n",
    "df['is_charge_date_holiday'] = df['charge_dt_holiday'].notnull().astype(int)\n",
    "df['is_flight_date_holiday'] = df['flight_dt_holiday'].notnull().astype(int)\n",
    "df.drop(['charge_dt_holiday', 'flight_dt_holiday'], axis=1, inplace=True)\n",
    "df = df.sort_values(by=['charge_dt', 'dtg'], ascending=[True, True])\n",
    "df.set_index('charge_dt', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130e08a0-96ea-4a54-bc26-4ef5a021296b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_sales = df.groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "plt.style.use('ggplot')\n",
    "total_sales.plot(style='-', figsize=(20,5), title = 'sales by charge date', y='unt_pre', x='charge_dt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49a916c1-99ba-4b28-a259-577cd2c6f4e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''df = df[df.index >= '2022-01-01']\n",
    "total_sales = df.groupby('charge_dt')[['unt_pre','promoseats']].sum()\n",
    "total_sales['promoseats'] = (total_sales['promoseats'] > 0).astype(int)\n",
    "total_sales['promo_change'] = total_sales['promoseats'].ne(total_sales['promoseats'].shift()).cumsum()\n",
    "promo_segments = total_sales.groupby('promo_change')\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.plot(total_sales.index, total_sales['unt_pre'], label='Sales')\n",
    "plt.title('Sales by Charge Date')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Shade background where promoseats == 1\n",
    "label_added = False\n",
    "for _, segment in promo_segments:\n",
    "    if segment['promoseats'].iloc[0] == 1:\n",
    "        start = segment.index[0]\n",
    "        end = segment.index[-1]\n",
    "        ax.axvspan(start, end, color='lightblue', alpha=1,  label='Promotion Period' if not label_added else None)\n",
    "        label_added = True\n",
    "\n",
    "ax.legend()\n",
    "plt.show()'''\n",
    "\n",
    "df = df[df.index >= '2022-01-01']\n",
    "total_sales_by_charge_dt = df.groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "plt.style.use('ggplot')\n",
    "total_sales_by_charge_dt.plot(style='-', figsize=(20,5), title = 'sales by charge date', y='unt_pre', x='charge_dt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04dc715-59c0-41b4-9233-7551663bd86e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['flight_dt'], axis=1, inplace=True)\n",
    "total_sales_by_dtg = df.groupby('dtg')['unt_pre'].sum().reset_index()\n",
    "plt.style.use('ggplot')\n",
    "total_sales_by_dtg.plot(style='-', figsize=(20,5), title = 'sales by dtg since 2022', y='unt_pre', x='dtg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25deb798-ce28-4204-a9d8-59d04c270f69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_reset = df.reset_index()\n",
    "df_reset['charge_dt'] = df_reset['charge_dt'].astype(str)\n",
    "\n",
    "fig = px.line(df_reset, \n",
    "                 x='dtg', \n",
    "                 y='unt_pre', \n",
    "                 animation_frame='charge_dt',  # Add dtg as an animation frame\n",
    "                 title='Sales by DTG with charge date variations')\n",
    "\n",
    "fig.update_xaxes(range=[0, 200])\n",
    "fig.update_yaxes(range=[0, 800])\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Days To Go',\n",
    "    yaxis_title='Sales',\n",
    "    legend_title='Charge Date',\n",
    "    height=900,\n",
    "    width=1400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a1bbd2-b12e-4540-87b0-98e548329f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming df is the original DataFrame\n",
    "df_melt = df.melt(id_vars='unt_pre', value_vars=['flight_month', 'charge_month'], var_name='month_type', value_name='month')\n",
    "\n",
    "# Group by month and month type, and calculate mean sales\n",
    "mean_sales = df_melt.groupby(['month', 'month_type'])['unt_pre'].mean().reset_index()\n",
    "\n",
    "# Convert 'month' to categorical for ordering\n",
    "mean_sales['month'] = pd.Categorical(mean_sales['month'], categories=[str(i) for i in range(1, 13)], ordered=True)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.barplot(data=mean_sales, x='month', y='unt_pre', hue='month_type')\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Mean Sales by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Mean Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0c9eb6-c222-4346-a611-dd1ed6cdabf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming df is the original DataFrame\n",
    "df_melt = df.melt(id_vars='unt_pre', value_vars=['flight_dow', 'charge_dow'], var_name='dow_type', value_name='dow')\n",
    "mean_sales = df_melt.groupby(['dow', 'dow_type'])['unt_pre'].mean().reset_index()\n",
    "mean_sales['dow'] = pd.Categorical(mean_sales['dow'], categories=[str(i) for i in range(0, 7)], ordered=True)\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=mean_sales, x='dow', y='unt_pre', hue='dow_type')\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Mean Sales by DoW')\n",
    "plt.xlabel('DoW')\n",
    "plt.ylabel('Mean Sales')\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b939ae4-ac68-49b0-8ffd-959811383a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by charge day of month and calculate mean sales\n",
    "mean_sales = df.groupby('charge_dom')['unt_pre'].mean().reset_index()\n",
    "mean_yield = df.groupby('charge_dom')['yield'].mean().reset_index()\n",
    "\n",
    "mean_sales['charge_dom'] = pd.to_numeric(mean_sales['charge_dom'])\n",
    "mean_yield['charge_dom'] = pd.to_numeric(mean_yield['charge_dom'])\n",
    "mean_sales = mean_sales.sort_values(by='charge_dom')\n",
    "mean_yield = mean_yield.sort_values(by='charge_dom')\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Plot mean sales\n",
    "ax1.plot(mean_sales['charge_dom'], mean_sales['unt_pre'], marker='o', linewidth=12, color='tab:red', label='Mean Sales')\n",
    "ax1.set_xlabel('Charge Day of Month')\n",
    "ax1.set_ylabel('Mean Sales', color='tab:red')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Create second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(mean_yield['charge_dom'], mean_yield['yield'], marker='s', linewidth=12, color='tab:blue', label='Mean Yield')\n",
    "ax2.set_ylabel('Mean Yield', color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Title and legend\n",
    "fig.suptitle('Mean Sales and Yield by Charge Day of Month (2022 - ToDate)')\n",
    "fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "# Plot the line graph\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(mean_sales['charge_dom'], mean_sales['unt_pre'], marker='o', linewidth=15)\n",
    "plt.title('Mean Sales by Charge Day of Month')\n",
    "plt.xlabel('Charge Day of Month')\n",
    "plt.ylabel('Mean Sales')\n",
    "display(plt.show())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a1b07e5-a271-4c24-9093-d374268dc7f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df.index > '2024-01-01') & (df.index < '2024-01-31')].groupby('charge_dt')['unt_pre'].mean().plot(figsize=(20,5), title = 'sales by charge date (Jan24)', y='unt_pre', linewidth=10)\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f56257-353a-43c0-8d7d-d11c9d3ae24a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['yield'], axis=1, inplace=True)\n",
    "cyclic_cols=['flight_dom', 'flight_doy', 'charge_dom', 'charge_doy', 'flight_month', 'charge_month', 'flight_dow', 'charge_dow']\n",
    "num_cols=['charge_year','flight_year', 'ty_capacity']\n",
    "\n",
    "def encode_cyclic_features(df, cyclic_cols):\n",
    "    for col in cyclic_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        max_val = df[col].max()\n",
    "        df[col + '_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "        df[col + '_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def scale_num_cols(df, num_cols, scaler=None):\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    else:\n",
    "        df[num_cols] = scaler.transform(df[num_cols])\n",
    "    return df, scaler\n",
    "\n",
    "encode_cyclic_features(df, cyclic_cols)\n",
    "df, scaler = scale_num_cols(df, num_cols)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de1e6f14-d693-4321-b457-d207d140c65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Error Metric\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c0a2e0-6d9c-40c3-afd6-3688882a64db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "split_date = pd.to_datetime(spark.sql(\"SELECT current_date()\").collect()[0][0]) - pd.DateOffset(days=168)\n",
    "train_prophet_plot = df.loc[df.index < split_date].groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "val_prophet_plot = df.loc[df.index >= split_date].groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(train_prophet_plot['charge_dt'],train_prophet_plot['unt_pre'], label='Train', color='blue')\n",
    "plt.plot(val_prophet_plot['charge_dt'], val_prophet_plot['unt_pre'], label='Validation', color='red')\n",
    "plt.axvline(pd.to_datetime(split_date), linestyle='--', color='black', label='Split Date')\n",
    "plt.legend()\n",
    "plt.title('Sales Before and After Split Date')\n",
    "plt.xlabel('Charge Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd31b82-3798-47f2-a101-9b2dc2965103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Prophet\n",
    "train_prophet = df.loc[df.index < split_date]\n",
    "val_prophet = df.loc[df.index >= split_date]\n",
    "train_df = train_prophet.reset_index()\n",
    "val_df = val_prophet.reset_index()\n",
    "all_forecasts = []\n",
    "\n",
    "for dtg_value in train_df['dtg'].unique():\n",
    "\n",
    "    train_subset = train_df[train_df['dtg'] == dtg_value][['charge_dt', 'unt_pre', 'ty_capacity', 'unt_pre_lag7', 'unt_pre_lag14', 'unt_pre_lag21', 'unt_pre_lag28']].copy()\n",
    "    train_subset.rename(columns={'charge_dt': 'ds', 'unt_pre': 'y'}, inplace=True)\n",
    "    train_subset.sort_values('ds', inplace=True)\n",
    "\n",
    "    val_subset = val_df[val_df['dtg'] == dtg_value][['charge_dt', 'ty_capacity', 'unt_pre_lag7', 'unt_pre_lag14', 'unt_pre_lag21', 'unt_pre_lag28']].copy()\n",
    "    val_subset.rename(columns={'charge_dt': 'ds'}, inplace=True)\n",
    "    val_subset.sort_values('ds', inplace=True)\n",
    "\n",
    "    if len(train_subset) < 10 or val_subset.empty:\n",
    "        continue\n",
    "\n",
    "    model = Prophet(holidays=holidays_df)\n",
    "    regressors = ['ty_capacity', 'unt_pre_lag7', 'unt_pre_lag14', 'unt_pre_lag21', 'unt_pre_lag28']\n",
    "    for reg in regressors:\n",
    "        model.add_regressor(reg)\n",
    "    model.fit(train_subset)\n",
    "\n",
    "    forecast = model.predict(val_subset)\n",
    "\n",
    "    forecast['dtg'] = dtg_value\n",
    "    forecast['actual'] = val_df[val_df['dtg'] == dtg_value].set_index('charge_dt').loc[forecast['ds'], 'unt_pre'].values\n",
    "\n",
    "    all_forecasts.append(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'dtg', 'actual']])\n",
    "\n",
    "prophet_val_forecasts = pd.concat(all_forecasts, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86e4ccec-7bbd-48fc-8fbc-8bb5307bdfd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_forecast = (prophet_val_forecasts.groupby('ds').agg({'yhat': 'sum','yhat_lower': 'sum', 'yhat_upper': 'sum'}).reset_index())\n",
    "actuals_all = pd.concat([train_df, val_df])\n",
    "actuals_all = actuals_all.rename(columns={'charge_dt': 'ds', 'unt_pre': 'y'})\n",
    "agg_actuals = (actuals_all.groupby('ds').agg({'y': 'sum'}).reset_index())\n",
    "plot_df = pd.merge(agg_forecast, agg_actuals, on='ds', how='outer').sort_values('ds')\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "\n",
    "plot_df_val = plot_df[plot_df['ds'] >= split_date]\n",
    "plot_df_train = plot_df[plot_df['ds'] < split_date]\n",
    "\n",
    "ax.plot(plot_df_val['ds'], plot_df_val['y'], 'k.', alpha=0.6, label='Actual')\n",
    "ax.plot(plot_df_train['ds'], plot_df_train['y'], 'red', linewidth=1.5, label='Train') \n",
    "\n",
    "ax.plot(plot_df['ds'], plot_df['yhat'], color='blue', label='Forecast')\n",
    "ax.fill_between(plot_df['ds'], plot_df['yhat_lower'], plot_df['yhat_upper'], color='skyblue', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "ax.axvline(x=split_date, color='black', linestyle='--', lw=2, label='Forecast Start')\n",
    "ax.set_title('Forecasted Demand with Prophet (Aggregated)', fontsize=18, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=14)\n",
    "ax.set_ylabel('Sales', fontsize=14)\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1baa0d31-52a2-4fe4-8f2a-17af29eb5235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Aggregate by charge date (ds)\n",
    "agg_forecasts = prophet_val_forecasts.groupby('ds').agg({\n",
    "    'yhat': 'sum',\n",
    "    'actual': 'sum',\n",
    "    'yhat_lower': 'sum',\n",
    "    'yhat_upper': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 2: Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(agg_forecasts['ds'], agg_forecasts['actual'], label='Actual', marker='o')\n",
    "plt.plot(agg_forecasts['ds'], agg_forecasts['yhat'], label='Forecast (Prophet)', marker='x')\n",
    "plt.xlabel('Charge Date')\n",
    "plt.ylabel('Total Sales Across All DTGs')\n",
    "plt.title('Prophet Forecast vs Actual â€“ Aggregated Over DTG')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92617e3e-b48e-4fc7-90a5-0fc380aa652f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mse_prophet = np.sqrt(mean_squared_error(prophet_val_forecasts['actual'], prophet_val_forecasts['yhat']))\n",
    "mape_prophet = mean_absolute_percentage_error(agg_forecasts['actual'], agg_forecasts['yhat'])\n",
    "print(f'MSE: {mse_prophet:.2f}')\n",
    "print(f'MAPE: {mape_prophet:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01fe76d8-c4d3-49f7-80a7-c4ae1c162fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''%python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.1],\n",
    "    #'subsample': [0.8, 1.0],\n",
    "    #'colsample_bytree': [0.8, 1.0],\n",
    "    #'lambda': [0.1, 1.0],\n",
    "    #'alpha': [0, 0.1],\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "outer_cv = TimeSeriesSplit(n_splits=5)\n",
    "inner_cv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "outer_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(df):\n",
    "    X_train_outer = df.iloc[train_idx].drop('unt_net', axis=1).copy()\n",
    "    y_train_outer = df.iloc[train_idx]['unt_net'].copy()\n",
    "    X_test_outer = df.iloc[test_idx].drop('unt_net', axis=1).copy()\n",
    "    y_test_outer = df.iloc[test_idx]['unt_net'].copy()\n",
    "\n",
    "    X_train_processed = preprocessor.fit_preprocess(X_train_outer)\n",
    "    X_test_processed = preprocessor.transform_preprocess(X_test_outer)\n",
    "\n",
    "    model = XGBRegressor(objective='reg:pseudohubererror', base_score=0.5, boosting='gbtree', early_stopping_rounds=50, max_depth=3, n_estimators=500, learning_rate=0.01)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, n_jobs=-1, verbose=1, scoring=rmse_scorer)\n",
    "\n",
    "    grid_search.fit(X_train_processed, y_train_outer, eval_set=[(X_test_processed, y_test_outer)])\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(X_test_processed, y_test_outer)\n",
    "    outer_scores.append(test_score)\n",
    "\n",
    "    print(f'Outer fold score: {test_score}, best params: {grid_search.best_params_}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "823b993d-9273-4a59-a826-2d6f9ae28cd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_dates = df.index.sort_values().unique()\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=168)\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(20, 10), sharex=True)\n",
    "plt.style.use('ggplot')\n",
    "fold=0\n",
    "preds = []\n",
    "scores = []\n",
    "# Nested cross-validation\n",
    "for train_index, val_index in tscv.split(unique_dates):\n",
    "\n",
    "    train_dates = unique_dates[train_index]\n",
    "    val_dates = unique_dates[val_index]\n",
    "\n",
    "    train_data = df.loc[train_dates]\n",
    "    val_data = df.loc[val_dates]\n",
    "\n",
    "    total_sales_train = train_data.groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "    total_sales_val = val_data.groupby('charge_dt')['unt_pre'].sum().reset_index()\n",
    "    total_sales_train.plot(ax=axs[fold], label='Train', x='charge_dt', y='unt_pre', style='-')\n",
    "    total_sales_val.plot(ax=axs[fold], label='Val', x='charge_dt', y='unt_pre', style='-')\n",
    "    axs[fold].axvline(val_data.index.min(), linestyle='--', color='black')\n",
    "    axs[fold].set_title(f'Fold {fold+1}')\n",
    "    fold += 1\n",
    "\n",
    "    X_train = train_data.drop('unt_pre', axis=1)\n",
    "    y_train = train_data['unt_pre']\n",
    "\n",
    "    X_test = val_data.drop('unt_pre', axis=1)\n",
    "    y_test = val_data['unt_pre']\n",
    "\n",
    "    model = xgb.XGBRegressor(base_score=0.5, booster ='gbtree', n_estimators=1000, early_stopping_rounds=50, max_depth=3, learning_rate=0.01, objective='reg:pseudohubererror', enable_categorical=True)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=100)\n",
    "\n",
    "    y_pred=model.predict(X_test)\n",
    "    preds.extend(y_pred)\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f14fc5-e055-4075-a260-5624280535b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_score = np.mean(scores)\n",
    "print(f'individual scores: {scores}')\n",
    "print(f'combined score: {np.mean(scores)}')\n",
    "print(f'std: {np.std(scores)}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b8a62d0-7c37-4379-bbb8-71ac38e5739d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'date': X_test.index, 'prediction': y_pred, 'dtg': X_test['dtg']})\n",
    "actual = pd.DataFrame({'date': X_test.index, 'unt_pre': y_test, 'dtg': X_test['dtg']})\n",
    "y_pred_total = predictions.groupby('date')['prediction'].sum().reset_index()\n",
    "y_test_total = actual.groupby('date')['unt_pre'].sum().reset_index()\n",
    "y_pred_total.set_index('date', inplace=True)\n",
    "y_test_total.set_index('date', inplace=True)\n",
    "mape_xgb = mean_absolute_percentage_error(y_test_total, y_pred_total)\n",
    "mse_xgb = np.sqrt(mean_squared_error(y_test_total, y_pred_total))\n",
    "print(f'MSE: {mse_xgb:.2f}')\n",
    "print(f'MAPE: {mape_xgb:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "179b85a0-70ea-47e1-9b6e-2b1b27f1b0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=model.feature_importances_, index=model.feature_names_in_, columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e33a7cdf-2ec1-4dee-b98e-2682e49a0a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_reset_actual = actual.reset_index()\n",
    "df_reset_actual['date'] = df_reset_actual['date'].astype(str)\n",
    "\n",
    "df_reset_pred = predictions.reset_index()\n",
    "df_reset_pred['date'] = df_reset_pred['date'].astype(str)\n",
    "\n",
    "df_plot_actual = df_reset_actual[df_reset_actual['unt_pre'].notnull()].copy()\n",
    "df_plot_pred = df_reset_pred[df_reset_pred['prediction'].notnull()].copy()\n",
    "\n",
    "df_actual = df_plot_actual[['date','dtg','unt_pre']].copy()\n",
    "df_actual['sales_type'] = 'actual'\n",
    "df_actual['sales_value'] = df_actual['unt_pre']\n",
    "\n",
    "df_pred = df_plot_pred[['date','dtg','prediction']].copy()\n",
    "df_pred['sales_type'] = 'predicted'\n",
    "df_pred['sales_value'] = df_pred['prediction']\n",
    "\n",
    "df_melted = pd.concat([df_actual, df_pred]).sort_values(['date','dtg','sales_type'])\n",
    "\n",
    "min_dtg = 0\n",
    "max_dtg = 200\n",
    "min_sales = 0\n",
    "max_sales = 800\n",
    "\n",
    "fig = px.line(df_melted, x='dtg', y='sales_value', color='sales_type', animation_frame='date', title='Actual vs Predicted by DTG across Charge Dates', color_discrete_map={'unt_net':'red', 'prediction':'blue'})\n",
    "fig.update_xaxes(range=[min_dtg, max_dtg], title='DTG')\n",
    "fig.update_yaxes(range=[min_sales, max_sales], title='Sales')\n",
    "fig.update_layout(legend_title='sales type', height=900, width=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce7acc3-1a29-43b0-b3ba-06a2b89ca7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "val_data['error'] = np.abs(y_test - y_pred)\n",
    "val_data.groupby(val_data.index)['error'].mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e0a8311-941c-484a-aa84-e963947bd02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "val_data.groupby(val_data.index)['error'].mean().plot(figsize=(20,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7085c6dc-140e-488f-82ad-572be4333900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future = pd.date_range(start=df.index.max() + pd.DateOffset(days=1), end=(df.index.max() + pd.DateOffset(days=1)), freq='1d')\n",
    "dtg_values = list(range(0, 301))\n",
    "future_combinations = list(product(future, dtg_values))\n",
    "future_df = pd.DataFrame(future_combinations, columns=['charge_dt', 'dtg'])\n",
    "create_features(future_df)\n",
    "encode_cyclic_features(future_df, cyclic_cols)\n",
    "future_df, _ = scale_num_cols(future_df, num_cols, scaler = joblib.load('scaler.pkl'))\n",
    "for lag in lag_periods:\n",
    "    future_df[f'lag{lag}'] = future_df.apply(lambda row: target_map.get((row.name - pd.Timedelta(f'{lag} day'), row['dtg']), None), axis=1)\n",
    "future_df['isFuture'] = True\n",
    "df['isFuture'] = False\n",
    "df_and_future = pd.concat([df, future_df])\n",
    "df_and_future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ac8a2d3-f696-4415-80d2-e41d4952a21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_w_features = df_and_future.query('isFuture').copy()\n",
    "future_w_features = future_w_features.drop(columns=['unt_pre', 'isFuture'])\n",
    "future_w_features['pred'] = model.predict(future_w_features)\n",
    "future_w_features.plot(figsize=(20,5), x='dtg', y='pred')\n",
    "plt.title('Predicted Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Apprenticeship Project (initial)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
